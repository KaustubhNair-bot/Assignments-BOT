# ğŸ“¡ Airtel RAG Customer Support Chatbot

A **Retrieval-Augmented Generation (RAG)** based customer support chatbot built for **Bharti Airtel** â€” India's leading telecom company. This project demonstrates an end-to-end RAG pipeline with evaluation, brand-voice prompting, and a Streamlit-based chat interface.

## ğŸ¯ Project Overview

**Use Case:** Customer Support Assistant for Airtel  
**Company:** Bharti Airtel Limited (Telecom)  
**Goal:** Build a RAG-based chatbot that answers customer queries about Airtel's plans, policies, billing, and services using only verified company documentation.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STREAMLIT UI                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚Mock Loginâ”‚â†’ â”‚Chat Interfaceâ”‚â†’â”‚Chunk Viewâ”‚  â”‚Eval Dashboardâ”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚                                          â”‚
â”‚                       â–¼                                          â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚            â”‚   User Query     â”‚                                  â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                     â”‚                                            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â–¼                       â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚  RAG Engine   â”‚    â”‚   LLM Engine      â”‚                     â”‚
â”‚  â”‚              â”‚    â”‚                    â”‚                      â”‚
â”‚  â”‚ â€¢ PDF Loader â”‚    â”‚ â€¢ Groq (LLaMA 3.3)â”‚                     â”‚
â”‚  â”‚ â€¢ Chunker    â”‚â”€â”€â”€â–¶â”‚ â€¢ Brand Persona    â”‚                     â”‚
â”‚  â”‚ â€¢ Embedder   â”‚    â”‚ â€¢ CoT Reasoning    â”‚                     â”‚
â”‚  â”‚ â€¢ FAISS DB   â”‚    â”‚ â€¢ Temp/TopP Ctrl   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                       â”‚                                â”‚
â”‚         â–¼                       â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ sentence-    â”‚    â”‚  Response with    â”‚                       â”‚
â”‚  â”‚ transformers â”‚    â”‚  CoT Reasoning    â”‚                       â”‚
â”‚  â”‚ (MiniLM-L6)  â”‚    â”‚  + Brand Voice    â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Tech Stack

| Component | Technology | Justification |
|-----------|-----------|---------------|
| **LLM** | Groq (LLaMA 3.3 70B Versatile) | Ultra-fast inference via Groq's LPU, excellent instruction-following. Cloud-based LLM chosen over SLM for superior reasoning and brand-voice adherence |
| **Embeddings** | `all-MiniLM-L6-v2` (SLM) | Lightweight (80MB), fast, 384-dim. Ideal for semantic search without GPU |
| **Vector DB** | FAISS (Facebook AI) | Fast similarity search, no server needed, persistent storage |
| **Chunking** | LangChain `RecursiveCharacterTextSplitter` | 500-char chunks with 100-char overlap for optimal retrieval |
| **UI** | Streamlit | Rapid prototyping, built-in chat components |
| **Auth** | Custom mock login (SHA-256) | Simple security gate as required |

## ğŸ§  Model Selection: LLM vs SLM

### Decision: **Hybrid Approach (LLM for generation + SLM for embeddings)**

| Aspect | LLM (LLaMA 3.3 70B via Groq) | SLM (MiniLM-L6-v2) |
|--------|------------------------|---------------------|
| **Used For** | Response generation | Document embeddings |
| **Why** | Superior brand-voice adherence, CoT reasoning, complex query handling | Fast, lightweight, no GPU needed, excellent for semantic similarity |
| **Size** | Cloud API (no local resources) | 80MB local model |
| **Latency** | ~0.5-2 seconds (Groq LPU) | ~50ms per embedding |
| **Cost** | Free tier available on Groq | Free (local) |

**Justification:** A pure SLM approach (e.g., Phi-2, TinyLlama) would struggle with:
- Maintaining consistent Airtel brand voice across varied queries
- Complex Chain-of-Thought reasoning
- Handling multi-turn conversations with context
- Generating detailed, structured responses

The hybrid approach gives us the best of both worlds: SLM efficiency for embeddings + LLM quality for generation.

## ğŸ“‹ Features

- âœ… **RAG Pipeline**: PDF loading â†’ Chunking â†’ Embedding â†’ FAISS â†’ Retrieval â†’ Generation
- âœ… **Brand Voice Persona**: Strict "Airtel Assist" persona that only uses provided context
- âœ… **Chain-of-Thought (CoT)**: Model explains retrieval logic before answering
- âœ… **Temperature/Top-P Controls**: Live sliders to experiment with generation parameters
- âœ… **Retrieved Chunks Display**: Dedicated tab showing source chunks with relevance scores
- âœ… **Mock Login**: Username/password authentication gate
- âœ… **Evaluation Suite**: 10-question benchmark with keyword matching & hallucination detection
- âœ… **Temperature Comparison**: Side-by-side comparison of factual vs. creative settings
- âœ… **Multi-turn Chat**: Conversation history maintained for context

## ğŸš€ Setup & Installation

### 1. Clone the repository
```bash
git clone https://github.com/KaustubhNair-bot/AI_Tr_BOT.git
cd AI_training_BOT/RAG_real_life_use_case_kaustubh
```

### 2. Create virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set up API key
```bash
cp .env.example .env
# Edit .env and add your Groq API key
# Get one at: https://console.groq.com/keys
```

### 5. Run the app
```bash
streamlit run streamlit_app.py
```

### 6. Login
Use any of these demo credentials:
| Username | Password | Role |
|----------|----------|------|
| `admin` | `admin123` | Administrator |
| `agent` | `agent123` | Customer Support |
| `demo` | `demo123` | Viewer |

## ğŸ“ Project Structure

```
RAG_real_life_use_case_kaustubh/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py          # Package init
â”‚   â”œâ”€â”€ auth.py              # Mock authentication module
â”‚   â”œâ”€â”€ rag_engine.py        # RAG pipeline (load, chunk, embed, FAISS, retrieve)
â”‚   â”œâ”€â”€ llm_engine.py        # Gemini LLM with brand persona & CoT
â”‚   â””â”€â”€ evaluation.py        # Benchmarking & hallucination detection
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ airtel_plans_and_policies.md   # Source document (Markdown)
â”‚   â””â”€â”€ airtel_plans_and_policies.pdf  # Source document (PDF)
â”œâ”€â”€ faiss_index/             # Persisted FAISS index (auto-generated)
â”œâ”€â”€ evaluation_results/      # Benchmark results (auto-generated)
â”œâ”€â”€ streamlit_app.py         # Main Streamlit application
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # API key template
â”œâ”€â”€ .gitignore               # Git ignore rules
â””â”€â”€ README.md                # This file
```

## ğŸ“Š Evaluation

The evaluation module (`app/evaluation.py`) tests the chatbot across 10 categories:

1. Prepaid Plans
2. Postpaid Plans
3. Porting / MNP
4. International Roaming
5. Refund Policy
6. Broadband
7. Customer Support
8. Rewards Program
9. Fair Usage Policy
10. Cancellation

### Metrics:
- **Keyword Match Score**: Percentage of expected keywords found in the response
- **Hallucination Rate**: Percentage of numeric claims not supported by retrieved chunks
- **Temperature Comparison**: Factual (T=0.0) vs Balanced (T=0.3) vs Creative (T=0.8)

## ğŸŒ¡ï¸ Generation Parameters Findings

| Setting | Temperature | Top-P | Hallucination Risk | Best For |
|---------|-------------|-------|-------------------|----------|
| Factual | 0.0 | 0.5 | âœ… Lowest | Plan details, pricing, policies |
| Balanced | 0.3 | 0.85 | âœ… Low | General queries, recommendations |
| Creative | 0.8 | 0.95 | âš ï¸ Higher | Marketing copy, engagement |

**Conclusion:** Temperature 0.0â€“0.3 with Top-P 0.5â€“0.85 provides the best balance of factual accuracy and brand-voice adherence for customer support.

## ğŸ”’ Security

- Mock login with SHA-256 hashed passwords
- Session-based authentication via Streamlit session state
- API key stored in `.env` (not committed to Git)
- Model constrained to only use provided context (reduces information leakage)

---

**Built by Kaustubh Nair** | AI Training Program â€” Week 3, Day 5 Assignment
